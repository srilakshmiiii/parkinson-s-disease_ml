# -*- coding: utf-8 -*-
"""Untitled23.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-nLzjgjwDSb_G5noKpftSToRSgTuXswA
"""

#QUSTION NUMER 1
#Parkinson's Data Set


import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, confusion_matrix
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import BaggingClassifier
from sklearn import tree

"""
This dataset is composed of a range of biomedical voice measurements from 31 people, 23 with
Parkinson's disease (PD). Each column in the table is a particular voice measure, and each row
corresponds to one of 195 voice recordings from these individuals ("name" column). The main aim
of the data is to discriminate healthy people from those with PD, according to the "status" column
which is set to 0 for healthy and 1 for PD.
The data is in ASCII CSV format. The rows of the CSV file contain an instance corresponding to
one voice recording. There are around six recordings per patient, the name of the patient is identified
in the first column."""

import pandas as pd

# Load the dataset
df = pd.read_csv("/content/parkinsons.csv")

df.head()

df.shape

# Exclude non-numeric columns before preprocessing
numeric_columns = data.select_dtypes(include=['float64', 'int64']).columns
data_numeric = df[numeric_columns]

# Handling missing values -- SimpleImputer to fill missing values with the mean of each column.
imputer = SimpleImputer(strategy='mean')
data_imputed = imputer.fit_transform(data_numeric)

# Standardization-- to standardize the data by scaling each feature to have a mean of 0 and a
# standard deviation of 1. This is important, especially for algorithms like Logistic Regression and SVM
scaler = StandardScaler()
data_scaled = scaler.fit_transform(data_imputed)

"""'name' column likely contains the names of individuals, which is not useful for modeling.
'status' column contains the labels (0 for healthy, 1 for Parkinson's), which is our target variable.
"""

X = df.drop(['name', 'status'], axis=1)
y = df['status']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) #splitting the data

# Assuming 'y_train' and 'y_test' are continuous values
# Convert them to discrete class labels based on a threshold

threshold = 0.5  # Threshold to convert continuous values to binary labels
y_train_binary = (y_train > threshold).astype(int)
y_test_binary = (y_test > threshold).astype(int)

# Initialize models
lr_model = LogisticRegression()
svm_model = SVC()
knn_model = KNeighborsClassifier()
mlp_model = MLPClassifier()
nb_model = GaussianNB()
pla_model = Perceptron()

# Train models
lr_model.fit(X_train, y_train_binary)
svm_model.fit(X_train, y_train_binary)
knn_model.fit(X_train, y_train_binary)
mlp_model.fit(X_train, y_train_binary)
nb_model.fit(X_train, y_train_binary)
pla_model.fit(X_train, y_train_binary)

# Step 8: Measure the performance of the trained model
#classification_report function generates a text report showing the main classification metrics: precision, recall, F1-score, and support.
#models dictionary contains the trained classification models as values, with their names as keys.

from sklearn.metrics import classification_report, accuracy_score

models = {
    'Logistic Regression': lr_model,
    'PLA': pla_model,
    'MLP': mlp_model,
    'KNN': knn_model,
    'SVM': svm_model,
    'Naive Bayes': nb_model
}

#evaluates the performance of each trained model on the test data and stores the results
#(accuracy and classification report) in a dictionary for further analysis and comparison.

results = {}
for name, model in models.items():
    y_pred = model.predict(X_test)
    accuracy = accuracy_score(y_test_binary, y_pred)
    report = classification_report(y_test_binary, y_pred)
    results[name] = {'accuracy': accuracy, 'classification_report': report}



# Print performance metrics
for name, result in results.items():
    print(f"Model: {name}")
    print(f"Accuracy: {result['accuracy']}")
    print(f"Classification Report:\n{result['classification_report']}")
    print("")

"""Best model from analysing the above mentioned performance metrices is Logistic Regression with accuracy of 89%."""

# Function to plot confusion matrix
def plot_confusion_matrix(y_true, y_pred, model_name):
    cm = confusion_matrix(y_true, y_pred)
    plt.figure(figsize=(6, 4))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)
    plt.title(f'Confusion Matrix - {model_name}')
    plt.xlabel('Predicted Label')
    plt.ylabel('True Label')
    plt.show()

# Plot confusion matrix for each model
for name, model in models.items():
    y_pred = model.predict(X_test)
    plot_confusion_matrix(y_test_binary, y_pred, name)

from sklearn.metrics import roc_curve, roc_auc_score

# Iterate over models and plot ROC curve for each model
for name, model in models.items():
    if hasattr(model, "predict_proba"):
        plt.figure(figsize=(6, 4))
        y_pred_proba = model.predict_proba(X_test)[:, 1]
        fpr, tpr, _ = roc_curve(y_test_binary, y_pred_proba)
        auc_score = roc_auc_score(y_test_binary, y_pred_proba)
        plt.plot(fpr, tpr, label=f"{name} (AUC = {auc_score:.2f})")
        plt.plot([0, 1], [0, 1], 'k--', label='Random')
        plt.xlabel('False Positive Rate')
        plt.ylabel('True Positive Rate')
        plt.title(f'Receiver Operating Characteristic (ROC) Curve - {name}')
        plt.legend()
        plt.show()

#clustering performance using the silhouette score

from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score

# Assuming X contains only the feature columns

# Initialize K-means model
kmeans = KMeans(n_clusters=2, random_state=42)

# Fit K-means model to the data
kmeans.fit(X)

# Get cluster labels
cluster_labels = kmeans.labels_

# Evaluate clustering performance using silhouette score
silhouette_avg = silhouette_score(X, cluster_labels)

print("Silhouette Score:", silhouette_avg)